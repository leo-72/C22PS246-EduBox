{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfomSavD5ogv"
      },
      "source": [
        "# Book Recommendation using TensorFlow Recommenders\n",
        "This notebook will demonstrate creating a Model for book recommendations using TensorFlow Recommenders with the [basic retriavel](https://www.tensorflow.org/recommenders/examples/basic_retrieval) method. We modified it to be able to recommend several books with 1 book title input.\n",
        "\n",
        "\n",
        "Retrieval models are often composed of two sub-models:\n",
        "\n",
        "1. A query model computing the query representation (normally a fixed-dimensionality embedding vector) using query features.\n",
        "2. A candidate model computing the candidate representation (an equally-sized vector) using the candidate features\n",
        "\n",
        "The outputs of the two models are then multiplied together to give a query-candidate affinity score, with higher scores expressing a better match between the candidate and the query. \n",
        "everyone who gives that rating also means that person reads the book. Every book a user read is a positive example, and every book they have not read is an implicit negative example. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "2MG0u3uXUMIz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aW7sa9Q84O7"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siHixmc53vFC"
      },
      "source": [
        "- Visit https://www.kaggle.com/datasets/zygmunt/goodbooks-10k\n",
        "- Click download button in the top right corner and the dataset will be downloaded in the form of a zip file\n",
        "- Find downloaded dataset and extract that file, there are several files, we just need books.csv and ratings.csv.\n",
        "- Open google drive and create a folder with the name \"Dataset\" and upload both files there."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import libraries"
      ],
      "metadata": {
        "id": "3CUSTNirUO_r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q6y36Xed9f5Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30845d5d-9cf7-484c-aa62-fdef4986e1d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▉                            | 10 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 20 kB 23.3 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 30 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 40 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 51 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 85 kB 2.9 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -q tensorflow-recommenders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2h82Bpbu9tKP"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_recommenders as tfrs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRa5Lfn736-c"
      },
      "source": [
        "## import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7UlsPuS3nsG",
        "outputId": "578d3314-09af-47d9-93d7-e9c79e2eeab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjcN0lik6UBN"
      },
      "source": [
        "## read files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "WjQgw2Zr2sGO",
        "outputId": "803f9e19-9e5d-469a-91b6-c93b78df347f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   book_id  user_id  rating\n",
              "0        1      314       5\n",
              "1        1      439       3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c07606c-593e-4338-9b4c-abfae348682c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>314</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>439</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c07606c-593e-4338-9b4c-abfae348682c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9c07606c-593e-4338-9b4c-abfae348682c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9c07606c-593e-4338-9b4c-abfae348682c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df_users = pd.read_csv(\n",
        "    \"./drive/MyDrive/Dataset/ratings.csv\"\n",
        ")\n",
        "df_users.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rq-x-Ory6eWr",
        "outputId": "1897dbba-3e0f-4380-ed51-f627cd17f3a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(981756, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df_users.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "LVIxcSDN4y9t",
        "outputId": "b89e3e89-2178-43c0-91d0-1f5248bd6ac7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  book_id  best_book_id  work_id  books_count       isbn        isbn13  \\\n",
              "0   1  2767052       2767052  2792775          272  439023483  9.780439e+12   \n",
              "1   2        3             3  4640799          491  439554934  9.780440e+12   \n",
              "\n",
              "                       authors  original_publication_year  \\\n",
              "0              Suzanne Collins                     2008.0   \n",
              "1  J.K. Rowling, Mary GrandPré                     1997.0   \n",
              "\n",
              "                             original_title  ... ratings_count  \\\n",
              "0                          The Hunger Games  ...       4780653   \n",
              "1  Harry Potter and the Philosopher's Stone  ...       4602479   \n",
              "\n",
              "  work_ratings_count  work_text_reviews_count  ratings_1  ratings_2  \\\n",
              "0            4942365                   155254      66715     127936   \n",
              "1            4800065                    75867      75504     101676   \n",
              "\n",
              "   ratings_3  ratings_4  ratings_5  \\\n",
              "0     560092    1481305    2706317   \n",
              "1     455024    1156318    3011543   \n",
              "\n",
              "                                           image_url  \\\n",
              "0  https://images.gr-assets.com/books/1447303603m...   \n",
              "1  https://images.gr-assets.com/books/1474154022m...   \n",
              "\n",
              "                                     small_image_url  \n",
              "0  https://images.gr-assets.com/books/1447303603s...  \n",
              "1  https://images.gr-assets.com/books/1474154022s...  \n",
              "\n",
              "[2 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc441f54-fea4-4631-a418-cdadb6f56540\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>book_id</th>\n",
              "      <th>best_book_id</th>\n",
              "      <th>work_id</th>\n",
              "      <th>books_count</th>\n",
              "      <th>isbn</th>\n",
              "      <th>isbn13</th>\n",
              "      <th>authors</th>\n",
              "      <th>original_publication_year</th>\n",
              "      <th>original_title</th>\n",
              "      <th>...</th>\n",
              "      <th>ratings_count</th>\n",
              "      <th>work_ratings_count</th>\n",
              "      <th>work_text_reviews_count</th>\n",
              "      <th>ratings_1</th>\n",
              "      <th>ratings_2</th>\n",
              "      <th>ratings_3</th>\n",
              "      <th>ratings_4</th>\n",
              "      <th>ratings_5</th>\n",
              "      <th>image_url</th>\n",
              "      <th>small_image_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2767052</td>\n",
              "      <td>2767052</td>\n",
              "      <td>2792775</td>\n",
              "      <td>272</td>\n",
              "      <td>439023483</td>\n",
              "      <td>9.780439e+12</td>\n",
              "      <td>Suzanne Collins</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>The Hunger Games</td>\n",
              "      <td>...</td>\n",
              "      <td>4780653</td>\n",
              "      <td>4942365</td>\n",
              "      <td>155254</td>\n",
              "      <td>66715</td>\n",
              "      <td>127936</td>\n",
              "      <td>560092</td>\n",
              "      <td>1481305</td>\n",
              "      <td>2706317</td>\n",
              "      <td>https://images.gr-assets.com/books/1447303603m...</td>\n",
              "      <td>https://images.gr-assets.com/books/1447303603s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4640799</td>\n",
              "      <td>491</td>\n",
              "      <td>439554934</td>\n",
              "      <td>9.780440e+12</td>\n",
              "      <td>J.K. Rowling, Mary GrandPré</td>\n",
              "      <td>1997.0</td>\n",
              "      <td>Harry Potter and the Philosopher's Stone</td>\n",
              "      <td>...</td>\n",
              "      <td>4602479</td>\n",
              "      <td>4800065</td>\n",
              "      <td>75867</td>\n",
              "      <td>75504</td>\n",
              "      <td>101676</td>\n",
              "      <td>455024</td>\n",
              "      <td>1156318</td>\n",
              "      <td>3011543</td>\n",
              "      <td>https://images.gr-assets.com/books/1474154022m...</td>\n",
              "      <td>https://images.gr-assets.com/books/1474154022s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc441f54-fea4-4631-a418-cdadb6f56540')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fc441f54-fea4-4631-a418-cdadb6f56540 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fc441f54-fea4-4631-a418-cdadb6f56540');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df_books = pd.read_csv(\n",
        "    \"./drive/MyDrive/Dataset/books.csv\"\n",
        ")\n",
        "df_books.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxhzRk785EhU",
        "outputId": "0796319d-b2d7-4a1f-8e66-2d5a49b7af72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 23)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df_books.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge the book dataframe to the user dataframe to retrieve the title."
      ],
      "metadata": {
        "id": "-msZKbOBREXn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "f9FHfhc8-aXf",
        "outputId": "993d9f44-3e74-47c2-dd66-6a4e4e44de56"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       book_id  user_id  rating    id  best_book_id  work_id  books_count  \\\n",
              "79699     9998    52330       4  8114          9998    58336           90   \n",
              "79700     9998    53249       5  8114          9998    58336           90   \n",
              "\n",
              "            isbn        isbn13                     authors  ...  \\\n",
              "79699  679733787  9.780680e+12  Kōbō Abe, E. Dale Saunders  ...   \n",
              "79700  679733787  9.780680e+12  Kōbō Abe, E. Dale Saunders  ...   \n",
              "\n",
              "       ratings_count work_ratings_count work_text_reviews_count ratings_1  \\\n",
              "79699          11467              13886                    1026       264   \n",
              "79700          11467              13886                    1026       264   \n",
              "\n",
              "       ratings_2  ratings_3  ratings_4  ratings_5  \\\n",
              "79699        838       3046       5523       4215   \n",
              "79700        838       3046       5523       4215   \n",
              "\n",
              "                                               image_url  \\\n",
              "79699  https://images.gr-assets.com/books/1361254930m...   \n",
              "79700  https://images.gr-assets.com/books/1361254930m...   \n",
              "\n",
              "                                         small_image_url  \n",
              "79699  https://images.gr-assets.com/books/1361254930s...  \n",
              "79700  https://images.gr-assets.com/books/1361254930s...  \n",
              "\n",
              "[2 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-937fa356-1e44-4c89-9598-97bcbb179833\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>id</th>\n",
              "      <th>best_book_id</th>\n",
              "      <th>work_id</th>\n",
              "      <th>books_count</th>\n",
              "      <th>isbn</th>\n",
              "      <th>isbn13</th>\n",
              "      <th>authors</th>\n",
              "      <th>...</th>\n",
              "      <th>ratings_count</th>\n",
              "      <th>work_ratings_count</th>\n",
              "      <th>work_text_reviews_count</th>\n",
              "      <th>ratings_1</th>\n",
              "      <th>ratings_2</th>\n",
              "      <th>ratings_3</th>\n",
              "      <th>ratings_4</th>\n",
              "      <th>ratings_5</th>\n",
              "      <th>image_url</th>\n",
              "      <th>small_image_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>79699</th>\n",
              "      <td>9998</td>\n",
              "      <td>52330</td>\n",
              "      <td>4</td>\n",
              "      <td>8114</td>\n",
              "      <td>9998</td>\n",
              "      <td>58336</td>\n",
              "      <td>90</td>\n",
              "      <td>679733787</td>\n",
              "      <td>9.780680e+12</td>\n",
              "      <td>Kōbō Abe, E. Dale Saunders</td>\n",
              "      <td>...</td>\n",
              "      <td>11467</td>\n",
              "      <td>13886</td>\n",
              "      <td>1026</td>\n",
              "      <td>264</td>\n",
              "      <td>838</td>\n",
              "      <td>3046</td>\n",
              "      <td>5523</td>\n",
              "      <td>4215</td>\n",
              "      <td>https://images.gr-assets.com/books/1361254930m...</td>\n",
              "      <td>https://images.gr-assets.com/books/1361254930s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79700</th>\n",
              "      <td>9998</td>\n",
              "      <td>53249</td>\n",
              "      <td>5</td>\n",
              "      <td>8114</td>\n",
              "      <td>9998</td>\n",
              "      <td>58336</td>\n",
              "      <td>90</td>\n",
              "      <td>679733787</td>\n",
              "      <td>9.780680e+12</td>\n",
              "      <td>Kōbō Abe, E. Dale Saunders</td>\n",
              "      <td>...</td>\n",
              "      <td>11467</td>\n",
              "      <td>13886</td>\n",
              "      <td>1026</td>\n",
              "      <td>264</td>\n",
              "      <td>838</td>\n",
              "      <td>3046</td>\n",
              "      <td>5523</td>\n",
              "      <td>4215</td>\n",
              "      <td>https://images.gr-assets.com/books/1361254930m...</td>\n",
              "      <td>https://images.gr-assets.com/books/1361254930s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-937fa356-1e44-4c89-9598-97bcbb179833')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-937fa356-1e44-4c89-9598-97bcbb179833 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-937fa356-1e44-4c89-9598-97bcbb179833');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_merged = df_users.merge(df_books, on=\"book_id\")\n",
        "df_merged.tail(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "Yq1PMC8Qixrz",
        "outputId": "9990c286-d4b2-4005-e3c0-7735aa0efd6d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       book_id  user_id  rating      original_title\n",
              "79699     9998    52330       4  砂の女 [Suna no onna]\n",
              "79700     9998    53249       5  砂の女 [Suna no onna]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-634cb433-862b-4491-a273-1fbcaa6d2c75\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>original_title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>79699</th>\n",
              "      <td>9998</td>\n",
              "      <td>52330</td>\n",
              "      <td>4</td>\n",
              "      <td>砂の女 [Suna no onna]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79700</th>\n",
              "      <td>9998</td>\n",
              "      <td>53249</td>\n",
              "      <td>5</td>\n",
              "      <td>砂の女 [Suna no onna]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-634cb433-862b-4491-a273-1fbcaa6d2c75')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-634cb433-862b-4491-a273-1fbcaa6d2c75 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-634cb433-862b-4491-a273-1fbcaa6d2c75');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df_merged.drop(df_merged.iloc[:, 3:11], inplace = True, axis = 1)\n",
        "df_merged.drop(df_merged.iloc[:, 4:], inplace = True, axis = 1)\n",
        "df_merged.tail(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvrLwLX18EW4"
      },
      "source": [
        "# create dataset objects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QD57U3zX_w4e"
      },
      "source": [
        "### create ratings dataset from df_merged"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zLgfa4fHMY9"
      },
      "source": [
        "Currently, the type of df_merged.user_id is int. To avoid error, we have to convert int to string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjMKIQRGhtaT",
        "outputId": "c75d4f7c-6929-4abc-a81a-58effa955ce2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "book_id            int64\n",
              "user_id            int64\n",
              "rating             int64\n",
              "original_title    object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df_merged.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "BPIYc8kmPmqx",
        "outputId": "9ef4f598-32a0-4f2b-f32b-2d96107b25c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   book_id user_id  rating                          original_title\n",
              "0        1     314       5  Harry Potter and the Half-Blood Prince\n",
              "1        1     439       3  Harry Potter and the Half-Blood Prince"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86e89603-4ef5-4857-a0bc-ccd04812678b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>original_title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>314</td>\n",
              "      <td>5</td>\n",
              "      <td>Harry Potter and the Half-Blood Prince</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>439</td>\n",
              "      <td>3</td>\n",
              "      <td>Harry Potter and the Half-Blood Prince</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86e89603-4ef5-4857-a0bc-ccd04812678b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86e89603-4ef5-4857-a0bc-ccd04812678b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86e89603-4ef5-4857-a0bc-ccd04812678b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df_merged.user_id = df_merged.user_id.astype(str)\n",
        "df_merged.original_title = df_merged.original_title.astype(str)\n",
        "df_merged.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYc39X2Ohwjv",
        "outputId": "fc6cb9aa-b7d1-4f43-d992-ed211248f09e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "book_id            int64\n",
              "user_id           object\n",
              "rating             int64\n",
              "original_title    object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df_merged.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use tf.data.Dataset.from_tensor_slices. We use df.to_dict('list') to convert the dataframe into a dictionary of (column_name, list_of_values)"
      ],
      "metadata": {
        "id": "ZCwcFfbkRSsv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "thJkIZYC8DM4"
      },
      "outputs": [],
      "source": [
        "users = tf.data.Dataset.from_tensor_slices({\n",
        "    \"user_id\": df_merged.user_id.tolist(),\n",
        "    \"original_title\": df_merged.original_title.tolist()\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ5KUgR79w_R",
        "outputId": "48ab7127-0c63-438a-c5e5-0f07c0a6afea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'original_title': b'Harry Potter and the Half-Blood Prince',\n",
              "  'user_id': b'314'},\n",
              " {'original_title': b'Harry Potter and the Half-Blood Prince',\n",
              "  'user_id': b'439'}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "list(users.take(2).as_numpy_iterator())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mapping data which will be used for embedding"
      ],
      "metadata": {
        "id": "afkB8-TSSEYu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4G3gb84_Fm1",
        "outputId": "4d52dbd7-3db0-4ef3-e666-aaab62b50f1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'original_title': b'Harry Potter and the Half-Blood Prince',\n",
              "  'user_id': b'314'},\n",
              " {'original_title': b'Harry Potter and the Half-Blood Prince',\n",
              "  'user_id': b'439'}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "users = users.map(lambda x: {\n",
        "    \"user_id\": x[\"user_id\"],\n",
        "    \"original_title\": x[\"original_title\"]\n",
        "})\n",
        "list(users.take(2).as_numpy_iterator())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilIJOtEy_0Rv"
      },
      "source": [
        "### books dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do the same for book data"
      ],
      "metadata": {
        "id": "c0v63wjGSLNl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EG0GH6M293rK"
      },
      "outputs": [],
      "source": [
        "df_books.original_title = df_books.original_title.astype(str)\n",
        "books = tf.data.Dataset.from_tensor_slices({\n",
        "    \"original_title\": df_books.original_title.tolist()\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wm-QnwMy-Gw5",
        "outputId": "c0495414-ef69-474e-8e41-36ef03f76eed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'original_title': b'The Hunger Games'},\n",
              " {'original_title': b\"Harry Potter and the Philosopher's Stone\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "list(books.take(2).as_numpy_iterator())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lo-dwBV-O8B",
        "outputId": "36cc6b22-784f-4625-8682-0830b9510956"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'The Hunger Games', b\"Harry Potter and the Philosopher's Stone\"]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "books = books.map(lambda x: x[\"original_title\"])\n",
        "list(books.take(2).as_numpy_iterator())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfqD_2evANRr"
      },
      "source": [
        "\n",
        "books dasaset needs to be unique. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yA-hoGqbAAX6",
        "outputId": "7f623c9e-db2f-443c-f260-9d4597efef73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'The Hunger Games', b\"Harry Potter and the Philosopher's Stone\"]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "books = books.unique()\n",
        "list(books.take(2).as_numpy_iterator())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV86WBh-KUL5"
      },
      "source": [
        "# Define our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS7hDsruA-qL"
      },
      "source": [
        "## get unique user_ids and book_titles"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is important because we need to be able to map the raw values ​​of our categorical features to embed vectors in our model. To do that, we need a vocabulary that maps raw feature values ​​to integers in a contiguous range: this allows us to search for the appropriate embedding in our embedding table."
      ],
      "metadata": {
        "id": "FTe_eXz4Sc3-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "aN0i_uAFA9dT"
      },
      "outputs": [],
      "source": [
        "user_ids = users.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
        "book_titles = books.batch(1_000)\n",
        "\n",
        "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
        "unique_book_titles = np.unique(np.concatenate(list(book_titles)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we are building a two-tower capture model, we can build each tower separately and then combine them in the final."
      ],
      "metadata": {
        "id": "8t32xR6LSfCl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "qQdc7Rm2AL2s"
      },
      "outputs": [],
      "source": [
        "class BookLensModel(tfrs.Model):\n",
        "  #We used the embedding dimension of 16 which is the best so far.\n",
        "    def __init__(self, embedding_dimension=16):\n",
        "        super().__init__()\n",
        "  #In query tower.\n",
        "  #We use Keras preprocessing layers to convert user id  and then convert those to user embeddings via an Embedding layer.\n",
        "  #we use the list of unique user ids we computed earlier as a vocabulary.\n",
        "        self.user_model = tf.keras.Sequential([\n",
        "            tf.keras.layers.StringLookup(vocabulary=unique_user_ids, mask_token=None),\n",
        "            tf.keras.layers.Embedding(len(unique_user_ids)+1, embedding_dimension)\n",
        "        ])\n",
        "  #We can do the same with the candidate tower.\n",
        "        self.book_model= tf.keras.Sequential([\n",
        "            tf.keras.layers.StringLookup(vocabulary=unique_book_titles, mask_token=None),\n",
        "            tf.keras.layers.Embedding(len(unique_book_titles)+1, embedding_dimension)\n",
        "        ])\n",
        "  #In our training data we have positive pairs (users, books). To find out how good our model is, \n",
        "  #we need to compare the model's calculated affinity score for this pair with the scores of all the other possible candidates.\n",
        "  #use of the Retrieval task object: a convenience wrapper that bundles together the loss function and metric computation\n",
        "  #The task itself is a Keras layer that takes the query and candidate embeddings as arguments, and returns the computed loss: we'll use that to implement the model's training loop.\n",
        "        self.task = tfrs.tasks.Retrieval(\n",
        "            metrics=tfrs.metrics.FactorizedTopK(\n",
        "                candidates=books.batch(128).map(self.book_model)\n",
        "            )\n",
        "        )\n",
        "  #implement the compute_loss method, taking in the raw features and returning a loss value.\n",
        "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "        user_embeddings = self.user_model(features[\"user_id\"])\n",
        "        book_embeddings = self.book_model(features[\"original_title\"])\n",
        "\n",
        "        return self.task(user_embeddings, book_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instantiate the model and define the compile attribute.\n"
      ],
      "metadata": {
        "id": "DZmbTYN0S70m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "On_yWDc4Dxsb"
      },
      "outputs": [],
      "source": [
        "model = BookLensModel()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTIqQIdBLb7U"
      },
      "source": [
        "# train our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TLwpjr7D-kg"
      },
      "source": [
        "In the case of image classification, we usually train the model with most of the data and validate/test it with a small amount of data or commonly known as unseen data. Validate/test with unseen data because later the model will predict images from users which of course are not in the train data.\n",
        "\n",
        "However, it is different in terms of recommendations, the data that will be predicted by the model is the data in the dataset. In our case, the book data that will be displayed in the application comes from the dataset used to create the model, so later the input that the user enters and what the model will process is the data in the dataset. So it would be better if we train the model with all the data in the dataset, this will make better predictions because the model predicts the previously seen data (seen data). It's also less useful to validate/test the model with unseen data, because user input will not be outside the dataset. And according to the source mentioned at the top of the page, there is only train and test(evaluate). Therefore, we will test(evaluate) with the seen data, just to make sure that the model will predict user input with such accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "KO6n6xgfJb2t"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "shuffled = users.shuffle(10000, seed=42, reshuffle_each_iteration=False)\n",
        "shuffledtest = shuffled.shuffle(2000, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(10000)\n",
        "test = shuffledtest.take(2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "zn1GYDzmD0lt"
      },
      "outputs": [],
      "source": [
        "\n",
        "cached_train = train.batch(4046).cache()\n",
        "cached_test = test.batch(4046).cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21hTjQlrD3CJ",
        "outputId": "367f862f-2311-4293-fa2f-4f7e7849ca42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "3/3 [==============================] - 8s 2s/step - factorized_top_k/top_1_categorical_accuracy: 1.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0045 - factorized_top_k/top_10_categorical_accuracy: 0.0121 - factorized_top_k/top_50_categorical_accuracy: 0.0361 - factorized_top_k/top_100_categorical_accuracy: 0.0523 - loss: 24007.9580 - regularization_loss: 0.0000e+00 - total_loss: 24007.9580\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0413 - factorized_top_k/top_10_categorical_accuracy: 0.1000 - factorized_top_k/top_50_categorical_accuracy: 0.5274 - factorized_top_k/top_100_categorical_accuracy: 0.6090 - loss: 23915.1865 - regularization_loss: 0.0000e+00 - total_loss: 23915.1865\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.2184 - factorized_top_k/top_10_categorical_accuracy: 0.3578 - factorized_top_k/top_50_categorical_accuracy: 0.8602 - factorized_top_k/top_100_categorical_accuracy: 0.9235 - loss: 23394.4502 - regularization_loss: 0.0000e+00 - total_loss: 23394.4502\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.3583 - factorized_top_k/top_10_categorical_accuracy: 0.5121 - factorized_top_k/top_50_categorical_accuracy: 0.9062 - factorized_top_k/top_100_categorical_accuracy: 0.9519 - loss: 22430.2417 - regularization_loss: 0.0000e+00 - total_loss: 22430.2417\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.4389 - factorized_top_k/top_10_categorical_accuracy: 0.6013 - factorized_top_k/top_50_categorical_accuracy: 0.9279 - factorized_top_k/top_100_categorical_accuracy: 0.9674 - loss: 21316.7095 - regularization_loss: 0.0000e+00 - total_loss: 21316.7095\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 8.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.4884 - factorized_top_k/top_10_categorical_accuracy: 0.6521 - factorized_top_k/top_50_categorical_accuracy: 0.9446 - factorized_top_k/top_100_categorical_accuracy: 0.9752 - loss: 20210.9097 - regularization_loss: 0.0000e+00 - total_loss: 20210.9097\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 8s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0020 - factorized_top_k/top_5_categorical_accuracy: 0.5249 - factorized_top_k/top_10_categorical_accuracy: 0.6847 - factorized_top_k/top_50_categorical_accuracy: 0.9556 - factorized_top_k/top_100_categorical_accuracy: 0.9823 - loss: 19212.8418 - regularization_loss: 0.0000e+00 - total_loss: 19212.8418\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 8s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0035 - factorized_top_k/top_5_categorical_accuracy: 0.5538 - factorized_top_k/top_10_categorical_accuracy: 0.7081 - factorized_top_k/top_50_categorical_accuracy: 0.9627 - factorized_top_k/top_100_categorical_accuracy: 0.9859 - loss: 18359.7422 - regularization_loss: 0.0000e+00 - total_loss: 18359.7422\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0053 - factorized_top_k/top_5_categorical_accuracy: 0.5732 - factorized_top_k/top_10_categorical_accuracy: 0.7294 - factorized_top_k/top_50_categorical_accuracy: 0.9671 - factorized_top_k/top_100_categorical_accuracy: 0.9888 - loss: 17658.2681 - regularization_loss: 0.0000e+00 - total_loss: 17658.2681\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0069 - factorized_top_k/top_5_categorical_accuracy: 0.5921 - factorized_top_k/top_10_categorical_accuracy: 0.7476 - factorized_top_k/top_50_categorical_accuracy: 0.9709 - factorized_top_k/top_100_categorical_accuracy: 0.9908 - loss: 17097.7485 - regularization_loss: 0.0000e+00 - total_loss: 17097.7485\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0107 - factorized_top_k/top_5_categorical_accuracy: 0.6101 - factorized_top_k/top_10_categorical_accuracy: 0.7623 - factorized_top_k/top_50_categorical_accuracy: 0.9736 - factorized_top_k/top_100_categorical_accuracy: 0.9921 - loss: 16655.0220 - regularization_loss: 0.0000e+00 - total_loss: 16655.0220\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0136 - factorized_top_k/top_5_categorical_accuracy: 0.6227 - factorized_top_k/top_10_categorical_accuracy: 0.7726 - factorized_top_k/top_50_categorical_accuracy: 0.9761 - factorized_top_k/top_100_categorical_accuracy: 0.9929 - loss: 16303.5654 - regularization_loss: 0.0000e+00 - total_loss: 16303.5654\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0152 - factorized_top_k/top_5_categorical_accuracy: 0.6321 - factorized_top_k/top_10_categorical_accuracy: 0.7817 - factorized_top_k/top_50_categorical_accuracy: 0.9783 - factorized_top_k/top_100_categorical_accuracy: 0.9936 - loss: 16020.6899 - regularization_loss: 0.0000e+00 - total_loss: 16020.6899\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0193 - factorized_top_k/top_5_categorical_accuracy: 0.6407 - factorized_top_k/top_10_categorical_accuracy: 0.7898 - factorized_top_k/top_50_categorical_accuracy: 0.9804 - factorized_top_k/top_100_categorical_accuracy: 0.9941 - loss: 15789.4253 - regularization_loss: 0.0000e+00 - total_loss: 15789.4253\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0241 - factorized_top_k/top_5_categorical_accuracy: 0.6499 - factorized_top_k/top_10_categorical_accuracy: 0.7956 - factorized_top_k/top_50_categorical_accuracy: 0.9814 - factorized_top_k/top_100_categorical_accuracy: 0.9946 - loss: 15597.5596 - regularization_loss: 0.0000e+00 - total_loss: 15597.5596\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0290 - factorized_top_k/top_5_categorical_accuracy: 0.6585 - factorized_top_k/top_10_categorical_accuracy: 0.8011 - factorized_top_k/top_50_categorical_accuracy: 0.9827 - factorized_top_k/top_100_categorical_accuracy: 0.9951 - loss: 15436.1909 - regularization_loss: 0.0000e+00 - total_loss: 15436.1909\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0336 - factorized_top_k/top_5_categorical_accuracy: 0.6648 - factorized_top_k/top_10_categorical_accuracy: 0.8059 - factorized_top_k/top_50_categorical_accuracy: 0.9835 - factorized_top_k/top_100_categorical_accuracy: 0.9959 - loss: 15298.7009 - regularization_loss: 0.0000e+00 - total_loss: 15298.7009\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0382 - factorized_top_k/top_5_categorical_accuracy: 0.6698 - factorized_top_k/top_10_categorical_accuracy: 0.8105 - factorized_top_k/top_50_categorical_accuracy: 0.9844 - factorized_top_k/top_100_categorical_accuracy: 0.9962 - loss: 15180.1245 - regularization_loss: 0.0000e+00 - total_loss: 15180.1245\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0421 - factorized_top_k/top_5_categorical_accuracy: 0.6739 - factorized_top_k/top_10_categorical_accuracy: 0.8128 - factorized_top_k/top_50_categorical_accuracy: 0.9853 - factorized_top_k/top_100_categorical_accuracy: 0.9963 - loss: 15076.7456 - regularization_loss: 0.0000e+00 - total_loss: 15076.7456\n",
            "Epoch 20/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0457 - factorized_top_k/top_5_categorical_accuracy: 0.6773 - factorized_top_k/top_10_categorical_accuracy: 0.8186 - factorized_top_k/top_50_categorical_accuracy: 0.9864 - factorized_top_k/top_100_categorical_accuracy: 0.9965 - loss: 14985.7712 - regularization_loss: 0.0000e+00 - total_loss: 14985.7712\n",
            "Epoch 21/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0528 - factorized_top_k/top_5_categorical_accuracy: 0.6820 - factorized_top_k/top_10_categorical_accuracy: 0.8231 - factorized_top_k/top_50_categorical_accuracy: 0.9869 - factorized_top_k/top_100_categorical_accuracy: 0.9966 - loss: 14905.0798 - regularization_loss: 0.0000e+00 - total_loss: 14905.0798\n",
            "Epoch 22/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0581 - factorized_top_k/top_5_categorical_accuracy: 0.6838 - factorized_top_k/top_10_categorical_accuracy: 0.8239 - factorized_top_k/top_50_categorical_accuracy: 0.9871 - factorized_top_k/top_100_categorical_accuracy: 0.9967 - loss: 14833.0195 - regularization_loss: 0.0000e+00 - total_loss: 14833.0195\n",
            "Epoch 23/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0637 - factorized_top_k/top_5_categorical_accuracy: 0.6870 - factorized_top_k/top_10_categorical_accuracy: 0.8265 - factorized_top_k/top_50_categorical_accuracy: 0.9876 - factorized_top_k/top_100_categorical_accuracy: 0.9968 - loss: 14768.2671 - regularization_loss: 0.0000e+00 - total_loss: 14768.2671\n",
            "Epoch 24/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0658 - factorized_top_k/top_5_categorical_accuracy: 0.6901 - factorized_top_k/top_10_categorical_accuracy: 0.8290 - factorized_top_k/top_50_categorical_accuracy: 0.9877 - factorized_top_k/top_100_categorical_accuracy: 0.9969 - loss: 14709.7358 - regularization_loss: 0.0000e+00 - total_loss: 14709.7358\n",
            "Epoch 25/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0672 - factorized_top_k/top_5_categorical_accuracy: 0.6922 - factorized_top_k/top_10_categorical_accuracy: 0.8316 - factorized_top_k/top_50_categorical_accuracy: 0.9879 - factorized_top_k/top_100_categorical_accuracy: 0.9970 - loss: 14656.5396 - regularization_loss: 0.0000e+00 - total_loss: 14656.5396\n",
            "Epoch 26/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0694 - factorized_top_k/top_5_categorical_accuracy: 0.6947 - factorized_top_k/top_10_categorical_accuracy: 0.8334 - factorized_top_k/top_50_categorical_accuracy: 0.9880 - factorized_top_k/top_100_categorical_accuracy: 0.9971 - loss: 14607.9307 - regularization_loss: 0.0000e+00 - total_loss: 14607.9307\n",
            "Epoch 27/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0706 - factorized_top_k/top_5_categorical_accuracy: 0.6973 - factorized_top_k/top_10_categorical_accuracy: 0.8357 - factorized_top_k/top_50_categorical_accuracy: 0.9884 - factorized_top_k/top_100_categorical_accuracy: 0.9971 - loss: 14563.2793 - regularization_loss: 0.0000e+00 - total_loss: 14563.2793\n",
            "Epoch 28/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0747 - factorized_top_k/top_5_categorical_accuracy: 0.6986 - factorized_top_k/top_10_categorical_accuracy: 0.8375 - factorized_top_k/top_50_categorical_accuracy: 0.9885 - factorized_top_k/top_100_categorical_accuracy: 0.9972 - loss: 14522.0945 - regularization_loss: 0.0000e+00 - total_loss: 14522.0945\n",
            "Epoch 29/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0766 - factorized_top_k/top_5_categorical_accuracy: 0.7012 - factorized_top_k/top_10_categorical_accuracy: 0.8385 - factorized_top_k/top_50_categorical_accuracy: 0.9888 - factorized_top_k/top_100_categorical_accuracy: 0.9973 - loss: 14483.9490 - regularization_loss: 0.0000e+00 - total_loss: 14483.9490\n",
            "Epoch 30/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0780 - factorized_top_k/top_5_categorical_accuracy: 0.7019 - factorized_top_k/top_10_categorical_accuracy: 0.8409 - factorized_top_k/top_50_categorical_accuracy: 0.9892 - factorized_top_k/top_100_categorical_accuracy: 0.9975 - loss: 14448.4983 - regularization_loss: 0.0000e+00 - total_loss: 14448.4983\n",
            "Epoch 31/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0803 - factorized_top_k/top_5_categorical_accuracy: 0.7033 - factorized_top_k/top_10_categorical_accuracy: 0.8426 - factorized_top_k/top_50_categorical_accuracy: 0.9893 - factorized_top_k/top_100_categorical_accuracy: 0.9975 - loss: 14415.4275 - regularization_loss: 0.0000e+00 - total_loss: 14415.4275\n",
            "Epoch 32/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0807 - factorized_top_k/top_5_categorical_accuracy: 0.7039 - factorized_top_k/top_10_categorical_accuracy: 0.8441 - factorized_top_k/top_50_categorical_accuracy: 0.9900 - factorized_top_k/top_100_categorical_accuracy: 0.9975 - loss: 14384.4961 - regularization_loss: 0.0000e+00 - total_loss: 14384.4961\n",
            "Epoch 33/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0863 - factorized_top_k/top_5_categorical_accuracy: 0.7052 - factorized_top_k/top_10_categorical_accuracy: 0.8449 - factorized_top_k/top_50_categorical_accuracy: 0.9903 - factorized_top_k/top_100_categorical_accuracy: 0.9975 - loss: 14355.4824 - regularization_loss: 0.0000e+00 - total_loss: 14355.4824\n",
            "Epoch 34/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0831 - factorized_top_k/top_5_categorical_accuracy: 0.7070 - factorized_top_k/top_10_categorical_accuracy: 0.8465 - factorized_top_k/top_50_categorical_accuracy: 0.9904 - factorized_top_k/top_100_categorical_accuracy: 0.9977 - loss: 14328.2100 - regularization_loss: 0.0000e+00 - total_loss: 14328.2100\n",
            "Epoch 35/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0896 - factorized_top_k/top_5_categorical_accuracy: 0.7077 - factorized_top_k/top_10_categorical_accuracy: 0.8468 - factorized_top_k/top_50_categorical_accuracy: 0.9907 - factorized_top_k/top_100_categorical_accuracy: 0.9977 - loss: 14302.4873 - regularization_loss: 0.0000e+00 - total_loss: 14302.4873\n",
            "Epoch 36/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0854 - factorized_top_k/top_5_categorical_accuracy: 0.7083 - factorized_top_k/top_10_categorical_accuracy: 0.8477 - factorized_top_k/top_50_categorical_accuracy: 0.9907 - factorized_top_k/top_100_categorical_accuracy: 0.9977 - loss: 14278.1985 - regularization_loss: 0.0000e+00 - total_loss: 14278.1985\n",
            "Epoch 37/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0940 - factorized_top_k/top_5_categorical_accuracy: 0.7090 - factorized_top_k/top_10_categorical_accuracy: 0.8488 - factorized_top_k/top_50_categorical_accuracy: 0.9907 - factorized_top_k/top_100_categorical_accuracy: 0.9979 - loss: 14255.2119 - regularization_loss: 0.0000e+00 - total_loss: 14255.2119\n",
            "Epoch 38/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0886 - factorized_top_k/top_5_categorical_accuracy: 0.7104 - factorized_top_k/top_10_categorical_accuracy: 0.8500 - factorized_top_k/top_50_categorical_accuracy: 0.9907 - factorized_top_k/top_100_categorical_accuracy: 0.9981 - loss: 14233.5032 - regularization_loss: 0.0000e+00 - total_loss: 14233.5032\n",
            "Epoch 39/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0983 - factorized_top_k/top_5_categorical_accuracy: 0.7110 - factorized_top_k/top_10_categorical_accuracy: 0.8515 - factorized_top_k/top_50_categorical_accuracy: 0.9910 - factorized_top_k/top_100_categorical_accuracy: 0.9982 - loss: 14212.8975 - regularization_loss: 0.0000e+00 - total_loss: 14212.8975\n",
            "Epoch 40/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0966 - factorized_top_k/top_5_categorical_accuracy: 0.7121 - factorized_top_k/top_10_categorical_accuracy: 0.8527 - factorized_top_k/top_50_categorical_accuracy: 0.9911 - factorized_top_k/top_100_categorical_accuracy: 0.9983 - loss: 14193.2156 - regularization_loss: 0.0000e+00 - total_loss: 14193.2156\n",
            "Epoch 41/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1013 - factorized_top_k/top_5_categorical_accuracy: 0.7133 - factorized_top_k/top_10_categorical_accuracy: 0.8530 - factorized_top_k/top_50_categorical_accuracy: 0.9912 - factorized_top_k/top_100_categorical_accuracy: 0.9985 - loss: 14174.4128 - regularization_loss: 0.0000e+00 - total_loss: 14174.4128\n",
            "Epoch 42/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0986 - factorized_top_k/top_5_categorical_accuracy: 0.7141 - factorized_top_k/top_10_categorical_accuracy: 0.8531 - factorized_top_k/top_50_categorical_accuracy: 0.9913 - factorized_top_k/top_100_categorical_accuracy: 0.9984 - loss: 14156.4626 - regularization_loss: 0.0000e+00 - total_loss: 14156.4626\n",
            "Epoch 43/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1027 - factorized_top_k/top_5_categorical_accuracy: 0.7147 - factorized_top_k/top_10_categorical_accuracy: 0.8545 - factorized_top_k/top_50_categorical_accuracy: 0.9913 - factorized_top_k/top_100_categorical_accuracy: 0.9985 - loss: 14139.2444 - regularization_loss: 0.0000e+00 - total_loss: 14139.2444\n",
            "Epoch 44/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0993 - factorized_top_k/top_5_categorical_accuracy: 0.7149 - factorized_top_k/top_10_categorical_accuracy: 0.8558 - factorized_top_k/top_50_categorical_accuracy: 0.9913 - factorized_top_k/top_100_categorical_accuracy: 0.9985 - loss: 14122.7158 - regularization_loss: 0.0000e+00 - total_loss: 14122.7158\n",
            "Epoch 45/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1047 - factorized_top_k/top_5_categorical_accuracy: 0.7162 - factorized_top_k/top_10_categorical_accuracy: 0.8572 - factorized_top_k/top_50_categorical_accuracy: 0.9913 - factorized_top_k/top_100_categorical_accuracy: 0.9985 - loss: 14106.8384 - regularization_loss: 0.0000e+00 - total_loss: 14106.8384\n",
            "Epoch 46/200\n",
            "3/3 [==============================] - 8s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.1011 - factorized_top_k/top_5_categorical_accuracy: 0.7165 - factorized_top_k/top_10_categorical_accuracy: 0.8582 - factorized_top_k/top_50_categorical_accuracy: 0.9914 - factorized_top_k/top_100_categorical_accuracy: 0.9985 - loss: 14091.6499 - regularization_loss: 0.0000e+00 - total_loss: 14091.6499\n",
            "Epoch 47/200\n",
            "3/3 [==============================] - 7s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1086 - factorized_top_k/top_5_categorical_accuracy: 0.7175 - factorized_top_k/top_10_categorical_accuracy: 0.8588 - factorized_top_k/top_50_categorical_accuracy: 0.9914 - factorized_top_k/top_100_categorical_accuracy: 0.9986 - loss: 14077.0723 - regularization_loss: 0.0000e+00 - total_loss: 14077.0723\n",
            "Epoch 48/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1071 - factorized_top_k/top_5_categorical_accuracy: 0.7185 - factorized_top_k/top_10_categorical_accuracy: 0.8597 - factorized_top_k/top_50_categorical_accuracy: 0.9914 - factorized_top_k/top_100_categorical_accuracy: 0.9986 - loss: 14063.0156 - regularization_loss: 0.0000e+00 - total_loss: 14063.0156\n",
            "Epoch 49/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1099 - factorized_top_k/top_5_categorical_accuracy: 0.7190 - factorized_top_k/top_10_categorical_accuracy: 0.8604 - factorized_top_k/top_50_categorical_accuracy: 0.9915 - factorized_top_k/top_100_categorical_accuracy: 0.9986 - loss: 14049.4207 - regularization_loss: 0.0000e+00 - total_loss: 14049.4207\n",
            "Epoch 50/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1092 - factorized_top_k/top_5_categorical_accuracy: 0.7202 - factorized_top_k/top_10_categorical_accuracy: 0.8610 - factorized_top_k/top_50_categorical_accuracy: 0.9915 - factorized_top_k/top_100_categorical_accuracy: 0.9986 - loss: 14036.3413 - regularization_loss: 0.0000e+00 - total_loss: 14036.3413\n",
            "Epoch 51/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1112 - factorized_top_k/top_5_categorical_accuracy: 0.7211 - factorized_top_k/top_10_categorical_accuracy: 0.8617 - factorized_top_k/top_50_categorical_accuracy: 0.9916 - factorized_top_k/top_100_categorical_accuracy: 0.9986 - loss: 14023.7371 - regularization_loss: 0.0000e+00 - total_loss: 14023.7371\n",
            "Epoch 52/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1113 - factorized_top_k/top_5_categorical_accuracy: 0.7228 - factorized_top_k/top_10_categorical_accuracy: 0.8630 - factorized_top_k/top_50_categorical_accuracy: 0.9917 - factorized_top_k/top_100_categorical_accuracy: 0.9986 - loss: 14011.5864 - regularization_loss: 0.0000e+00 - total_loss: 14011.5864\n",
            "Epoch 53/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1118 - factorized_top_k/top_5_categorical_accuracy: 0.7227 - factorized_top_k/top_10_categorical_accuracy: 0.8628 - factorized_top_k/top_50_categorical_accuracy: 0.9917 - factorized_top_k/top_100_categorical_accuracy: 0.9988 - loss: 13999.8438 - regularization_loss: 0.0000e+00 - total_loss: 13999.8438\n",
            "Epoch 54/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1130 - factorized_top_k/top_5_categorical_accuracy: 0.7237 - factorized_top_k/top_10_categorical_accuracy: 0.8641 - factorized_top_k/top_50_categorical_accuracy: 0.9918 - factorized_top_k/top_100_categorical_accuracy: 0.9988 - loss: 13988.4907 - regularization_loss: 0.0000e+00 - total_loss: 13988.4907\n",
            "Epoch 55/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1139 - factorized_top_k/top_5_categorical_accuracy: 0.7246 - factorized_top_k/top_10_categorical_accuracy: 0.8645 - factorized_top_k/top_50_categorical_accuracy: 0.9920 - factorized_top_k/top_100_categorical_accuracy: 0.9988 - loss: 13977.5100 - regularization_loss: 0.0000e+00 - total_loss: 13977.5100\n",
            "Epoch 56/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1138 - factorized_top_k/top_5_categorical_accuracy: 0.7256 - factorized_top_k/top_10_categorical_accuracy: 0.8651 - factorized_top_k/top_50_categorical_accuracy: 0.9921 - factorized_top_k/top_100_categorical_accuracy: 0.9989 - loss: 13966.8718 - regularization_loss: 0.0000e+00 - total_loss: 13966.8718\n",
            "Epoch 57/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1147 - factorized_top_k/top_5_categorical_accuracy: 0.7259 - factorized_top_k/top_10_categorical_accuracy: 0.8657 - factorized_top_k/top_50_categorical_accuracy: 0.9921 - factorized_top_k/top_100_categorical_accuracy: 0.9990 - loss: 13956.5596 - regularization_loss: 0.0000e+00 - total_loss: 13956.5596\n",
            "Epoch 58/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1148 - factorized_top_k/top_5_categorical_accuracy: 0.7258 - factorized_top_k/top_10_categorical_accuracy: 0.8667 - factorized_top_k/top_50_categorical_accuracy: 0.9922 - factorized_top_k/top_100_categorical_accuracy: 0.9990 - loss: 13946.5637 - regularization_loss: 0.0000e+00 - total_loss: 13946.5637\n",
            "Epoch 59/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1153 - factorized_top_k/top_5_categorical_accuracy: 0.7263 - factorized_top_k/top_10_categorical_accuracy: 0.8672 - factorized_top_k/top_50_categorical_accuracy: 0.9922 - factorized_top_k/top_100_categorical_accuracy: 0.9990 - loss: 13936.8486 - regularization_loss: 0.0000e+00 - total_loss: 13936.8486\n",
            "Epoch 60/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1151 - factorized_top_k/top_5_categorical_accuracy: 0.7267 - factorized_top_k/top_10_categorical_accuracy: 0.8676 - factorized_top_k/top_50_categorical_accuracy: 0.9924 - factorized_top_k/top_100_categorical_accuracy: 0.9990 - loss: 13927.4280 - regularization_loss: 0.0000e+00 - total_loss: 13927.4280\n",
            "Epoch 61/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1162 - factorized_top_k/top_5_categorical_accuracy: 0.7266 - factorized_top_k/top_10_categorical_accuracy: 0.8682 - factorized_top_k/top_50_categorical_accuracy: 0.9924 - factorized_top_k/top_100_categorical_accuracy: 0.9990 - loss: 13918.2566 - regularization_loss: 0.0000e+00 - total_loss: 13918.2566\n",
            "Epoch 62/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1162 - factorized_top_k/top_5_categorical_accuracy: 0.7273 - factorized_top_k/top_10_categorical_accuracy: 0.8687 - factorized_top_k/top_50_categorical_accuracy: 0.9924 - factorized_top_k/top_100_categorical_accuracy: 0.9990 - loss: 13909.3530 - regularization_loss: 0.0000e+00 - total_loss: 13909.3530\n",
            "Epoch 63/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1165 - factorized_top_k/top_5_categorical_accuracy: 0.7280 - factorized_top_k/top_10_categorical_accuracy: 0.8693 - factorized_top_k/top_50_categorical_accuracy: 0.9925 - factorized_top_k/top_100_categorical_accuracy: 0.9990 - loss: 13900.6772 - regularization_loss: 0.0000e+00 - total_loss: 13900.6772\n",
            "Epoch 64/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1172 - factorized_top_k/top_5_categorical_accuracy: 0.7289 - factorized_top_k/top_10_categorical_accuracy: 0.8700 - factorized_top_k/top_50_categorical_accuracy: 0.9926 - factorized_top_k/top_100_categorical_accuracy: 0.9990 - loss: 13892.2422 - regularization_loss: 0.0000e+00 - total_loss: 13892.2422\n",
            "Epoch 65/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1173 - factorized_top_k/top_5_categorical_accuracy: 0.7291 - factorized_top_k/top_10_categorical_accuracy: 0.8703 - factorized_top_k/top_50_categorical_accuracy: 0.9927 - factorized_top_k/top_100_categorical_accuracy: 0.9990 - loss: 13884.0222 - regularization_loss: 0.0000e+00 - total_loss: 13884.0222\n",
            "Epoch 66/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1183 - factorized_top_k/top_5_categorical_accuracy: 0.7297 - factorized_top_k/top_10_categorical_accuracy: 0.8718 - factorized_top_k/top_50_categorical_accuracy: 0.9927 - factorized_top_k/top_100_categorical_accuracy: 0.9990 - loss: 13876.0156 - regularization_loss: 0.0000e+00 - total_loss: 13876.0156\n",
            "Epoch 67/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1184 - factorized_top_k/top_5_categorical_accuracy: 0.7305 - factorized_top_k/top_10_categorical_accuracy: 0.8727 - factorized_top_k/top_50_categorical_accuracy: 0.9929 - factorized_top_k/top_100_categorical_accuracy: 0.9990 - loss: 13868.2163 - regularization_loss: 0.0000e+00 - total_loss: 13868.2163\n",
            "Epoch 68/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1185 - factorized_top_k/top_5_categorical_accuracy: 0.7307 - factorized_top_k/top_10_categorical_accuracy: 0.8733 - factorized_top_k/top_50_categorical_accuracy: 0.9929 - factorized_top_k/top_100_categorical_accuracy: 0.9990 - loss: 13860.6021 - regularization_loss: 0.0000e+00 - total_loss: 13860.6021\n",
            "Epoch 69/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1192 - factorized_top_k/top_5_categorical_accuracy: 0.7309 - factorized_top_k/top_10_categorical_accuracy: 0.8737 - factorized_top_k/top_50_categorical_accuracy: 0.9930 - factorized_top_k/top_100_categorical_accuracy: 0.9990 - loss: 13853.1868 - regularization_loss: 0.0000e+00 - total_loss: 13853.1868\n",
            "Epoch 70/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1187 - factorized_top_k/top_5_categorical_accuracy: 0.7313 - factorized_top_k/top_10_categorical_accuracy: 0.8739 - factorized_top_k/top_50_categorical_accuracy: 0.9930 - factorized_top_k/top_100_categorical_accuracy: 0.9990 - loss: 13845.9331 - regularization_loss: 0.0000e+00 - total_loss: 13845.9331\n",
            "Epoch 71/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1198 - factorized_top_k/top_5_categorical_accuracy: 0.7314 - factorized_top_k/top_10_categorical_accuracy: 0.8746 - factorized_top_k/top_50_categorical_accuracy: 0.9930 - factorized_top_k/top_100_categorical_accuracy: 0.9990 - loss: 13838.8708 - regularization_loss: 0.0000e+00 - total_loss: 13838.8708\n",
            "Epoch 72/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1195 - factorized_top_k/top_5_categorical_accuracy: 0.7318 - factorized_top_k/top_10_categorical_accuracy: 0.8750 - factorized_top_k/top_50_categorical_accuracy: 0.9931 - factorized_top_k/top_100_categorical_accuracy: 0.9990 - loss: 13831.9502 - regularization_loss: 0.0000e+00 - total_loss: 13831.9502\n",
            "Epoch 73/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1201 - factorized_top_k/top_5_categorical_accuracy: 0.7321 - factorized_top_k/top_10_categorical_accuracy: 0.8753 - factorized_top_k/top_50_categorical_accuracy: 0.9931 - factorized_top_k/top_100_categorical_accuracy: 0.9990 - loss: 13825.2097 - regularization_loss: 0.0000e+00 - total_loss: 13825.2097\n",
            "Epoch 74/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1197 - factorized_top_k/top_5_categorical_accuracy: 0.7326 - factorized_top_k/top_10_categorical_accuracy: 0.8753 - factorized_top_k/top_50_categorical_accuracy: 0.9931 - factorized_top_k/top_100_categorical_accuracy: 0.9990 - loss: 13818.5908 - regularization_loss: 0.0000e+00 - total_loss: 13818.5908\n",
            "Epoch 75/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1212 - factorized_top_k/top_5_categorical_accuracy: 0.7333 - factorized_top_k/top_10_categorical_accuracy: 0.8755 - factorized_top_k/top_50_categorical_accuracy: 0.9931 - factorized_top_k/top_100_categorical_accuracy: 0.9991 - loss: 13812.1533 - regularization_loss: 0.0000e+00 - total_loss: 13812.1533\n",
            "Epoch 76/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1208 - factorized_top_k/top_5_categorical_accuracy: 0.7338 - factorized_top_k/top_10_categorical_accuracy: 0.8757 - factorized_top_k/top_50_categorical_accuracy: 0.9932 - factorized_top_k/top_100_categorical_accuracy: 0.9991 - loss: 13805.8149 - regularization_loss: 0.0000e+00 - total_loss: 13805.8149\n",
            "Epoch 77/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1229 - factorized_top_k/top_5_categorical_accuracy: 0.7345 - factorized_top_k/top_10_categorical_accuracy: 0.8759 - factorized_top_k/top_50_categorical_accuracy: 0.9934 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13799.6567 - regularization_loss: 0.0000e+00 - total_loss: 13799.6567\n",
            "Epoch 78/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1220 - factorized_top_k/top_5_categorical_accuracy: 0.7342 - factorized_top_k/top_10_categorical_accuracy: 0.8762 - factorized_top_k/top_50_categorical_accuracy: 0.9935 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13793.5791 - regularization_loss: 0.0000e+00 - total_loss: 13793.5791\n",
            "Epoch 79/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1231 - factorized_top_k/top_5_categorical_accuracy: 0.7352 - factorized_top_k/top_10_categorical_accuracy: 0.8765 - factorized_top_k/top_50_categorical_accuracy: 0.9935 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13787.6797 - regularization_loss: 0.0000e+00 - total_loss: 13787.6797\n",
            "Epoch 80/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1221 - factorized_top_k/top_5_categorical_accuracy: 0.7355 - factorized_top_k/top_10_categorical_accuracy: 0.8769 - factorized_top_k/top_50_categorical_accuracy: 0.9936 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13781.8433 - regularization_loss: 0.0000e+00 - total_loss: 13781.8433\n",
            "Epoch 81/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1243 - factorized_top_k/top_5_categorical_accuracy: 0.7362 - factorized_top_k/top_10_categorical_accuracy: 0.8770 - factorized_top_k/top_50_categorical_accuracy: 0.9938 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13776.1846 - regularization_loss: 0.0000e+00 - total_loss: 13776.1846\n",
            "Epoch 82/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1233 - factorized_top_k/top_5_categorical_accuracy: 0.7361 - factorized_top_k/top_10_categorical_accuracy: 0.8776 - factorized_top_k/top_50_categorical_accuracy: 0.9938 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13770.5769 - regularization_loss: 0.0000e+00 - total_loss: 13770.5769\n",
            "Epoch 83/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1245 - factorized_top_k/top_5_categorical_accuracy: 0.7367 - factorized_top_k/top_10_categorical_accuracy: 0.8780 - factorized_top_k/top_50_categorical_accuracy: 0.9939 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13765.1443 - regularization_loss: 0.0000e+00 - total_loss: 13765.1443\n",
            "Epoch 84/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1238 - factorized_top_k/top_5_categorical_accuracy: 0.7371 - factorized_top_k/top_10_categorical_accuracy: 0.8782 - factorized_top_k/top_50_categorical_accuracy: 0.9939 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13759.7485 - regularization_loss: 0.0000e+00 - total_loss: 13759.7485\n",
            "Epoch 85/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1248 - factorized_top_k/top_5_categorical_accuracy: 0.7372 - factorized_top_k/top_10_categorical_accuracy: 0.8784 - factorized_top_k/top_50_categorical_accuracy: 0.9940 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13754.5251 - regularization_loss: 0.0000e+00 - total_loss: 13754.5251\n",
            "Epoch 86/200\n",
            "3/3 [==============================] - 8s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.1244 - factorized_top_k/top_5_categorical_accuracy: 0.7377 - factorized_top_k/top_10_categorical_accuracy: 0.8789 - factorized_top_k/top_50_categorical_accuracy: 0.9941 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13749.3276 - regularization_loss: 0.0000e+00 - total_loss: 13749.3276\n",
            "Epoch 87/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1250 - factorized_top_k/top_5_categorical_accuracy: 0.7379 - factorized_top_k/top_10_categorical_accuracy: 0.8790 - factorized_top_k/top_50_categorical_accuracy: 0.9942 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13744.2964 - regularization_loss: 0.0000e+00 - total_loss: 13744.2964\n",
            "Epoch 88/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1247 - factorized_top_k/top_5_categorical_accuracy: 0.7383 - factorized_top_k/top_10_categorical_accuracy: 0.8793 - factorized_top_k/top_50_categorical_accuracy: 0.9943 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13739.2856 - regularization_loss: 0.0000e+00 - total_loss: 13739.2856\n",
            "Epoch 89/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1255 - factorized_top_k/top_5_categorical_accuracy: 0.7387 - factorized_top_k/top_10_categorical_accuracy: 0.8793 - factorized_top_k/top_50_categorical_accuracy: 0.9944 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13734.4368 - regularization_loss: 0.0000e+00 - total_loss: 13734.4368\n",
            "Epoch 90/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1253 - factorized_top_k/top_5_categorical_accuracy: 0.7391 - factorized_top_k/top_10_categorical_accuracy: 0.8800 - factorized_top_k/top_50_categorical_accuracy: 0.9944 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13729.6003 - regularization_loss: 0.0000e+00 - total_loss: 13729.6003\n",
            "Epoch 91/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1258 - factorized_top_k/top_5_categorical_accuracy: 0.7393 - factorized_top_k/top_10_categorical_accuracy: 0.8809 - factorized_top_k/top_50_categorical_accuracy: 0.9944 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13724.9221 - regularization_loss: 0.0000e+00 - total_loss: 13724.9221\n",
            "Epoch 92/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1251 - factorized_top_k/top_5_categorical_accuracy: 0.7397 - factorized_top_k/top_10_categorical_accuracy: 0.8815 - factorized_top_k/top_50_categorical_accuracy: 0.9944 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13720.2517 - regularization_loss: 0.0000e+00 - total_loss: 13720.2517\n",
            "Epoch 93/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1268 - factorized_top_k/top_5_categorical_accuracy: 0.7397 - factorized_top_k/top_10_categorical_accuracy: 0.8816 - factorized_top_k/top_50_categorical_accuracy: 0.9944 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13715.7300 - regularization_loss: 0.0000e+00 - total_loss: 13715.7300\n",
            "Epoch 94/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1258 - factorized_top_k/top_5_categorical_accuracy: 0.7401 - factorized_top_k/top_10_categorical_accuracy: 0.8816 - factorized_top_k/top_50_categorical_accuracy: 0.9944 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13711.2202 - regularization_loss: 0.0000e+00 - total_loss: 13711.2202\n",
            "Epoch 95/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1275 - factorized_top_k/top_5_categorical_accuracy: 0.7404 - factorized_top_k/top_10_categorical_accuracy: 0.8821 - factorized_top_k/top_50_categorical_accuracy: 0.9944 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13706.8420 - regularization_loss: 0.0000e+00 - total_loss: 13706.8420\n",
            "Epoch 96/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1263 - factorized_top_k/top_5_categorical_accuracy: 0.7406 - factorized_top_k/top_10_categorical_accuracy: 0.8821 - factorized_top_k/top_50_categorical_accuracy: 0.9944 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13702.4851 - regularization_loss: 0.0000e+00 - total_loss: 13702.4851\n",
            "Epoch 97/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1280 - factorized_top_k/top_5_categorical_accuracy: 0.7406 - factorized_top_k/top_10_categorical_accuracy: 0.8823 - factorized_top_k/top_50_categorical_accuracy: 0.9944 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13698.2405 - regularization_loss: 0.0000e+00 - total_loss: 13698.2405\n",
            "Epoch 98/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1265 - factorized_top_k/top_5_categorical_accuracy: 0.7413 - factorized_top_k/top_10_categorical_accuracy: 0.8828 - factorized_top_k/top_50_categorical_accuracy: 0.9944 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13694.0303 - regularization_loss: 0.0000e+00 - total_loss: 13694.0303\n",
            "Epoch 99/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1283 - factorized_top_k/top_5_categorical_accuracy: 0.7415 - factorized_top_k/top_10_categorical_accuracy: 0.8827 - factorized_top_k/top_50_categorical_accuracy: 0.9945 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13689.9148 - regularization_loss: 0.0000e+00 - total_loss: 13689.9148\n",
            "Epoch 100/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1271 - factorized_top_k/top_5_categorical_accuracy: 0.7416 - factorized_top_k/top_10_categorical_accuracy: 0.8829 - factorized_top_k/top_50_categorical_accuracy: 0.9946 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13685.8472 - regularization_loss: 0.0000e+00 - total_loss: 13685.8472\n",
            "Epoch 101/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1288 - factorized_top_k/top_5_categorical_accuracy: 0.7416 - factorized_top_k/top_10_categorical_accuracy: 0.8834 - factorized_top_k/top_50_categorical_accuracy: 0.9947 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13681.8540 - regularization_loss: 0.0000e+00 - total_loss: 13681.8540\n",
            "Epoch 102/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1268 - factorized_top_k/top_5_categorical_accuracy: 0.7415 - factorized_top_k/top_10_categorical_accuracy: 0.8832 - factorized_top_k/top_50_categorical_accuracy: 0.9947 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13677.9214 - regularization_loss: 0.0000e+00 - total_loss: 13677.9214\n",
            "Epoch 103/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1294 - factorized_top_k/top_5_categorical_accuracy: 0.7415 - factorized_top_k/top_10_categorical_accuracy: 0.8834 - factorized_top_k/top_50_categorical_accuracy: 0.9947 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13674.0461 - regularization_loss: 0.0000e+00 - total_loss: 13674.0461\n",
            "Epoch 104/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1268 - factorized_top_k/top_5_categorical_accuracy: 0.7416 - factorized_top_k/top_10_categorical_accuracy: 0.8839 - factorized_top_k/top_50_categorical_accuracy: 0.9947 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13670.2388 - regularization_loss: 0.0000e+00 - total_loss: 13670.2388\n",
            "Epoch 105/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1291 - factorized_top_k/top_5_categorical_accuracy: 0.7415 - factorized_top_k/top_10_categorical_accuracy: 0.8844 - factorized_top_k/top_50_categorical_accuracy: 0.9948 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13666.4751 - regularization_loss: 0.0000e+00 - total_loss: 13666.4751\n",
            "Epoch 106/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1269 - factorized_top_k/top_5_categorical_accuracy: 0.7418 - factorized_top_k/top_10_categorical_accuracy: 0.8849 - factorized_top_k/top_50_categorical_accuracy: 0.9948 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13662.7803 - regularization_loss: 0.0000e+00 - total_loss: 13662.7803\n",
            "Epoch 107/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1289 - factorized_top_k/top_5_categorical_accuracy: 0.7420 - factorized_top_k/top_10_categorical_accuracy: 0.8853 - factorized_top_k/top_50_categorical_accuracy: 0.9948 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13659.1265 - regularization_loss: 0.0000e+00 - total_loss: 13659.1265\n",
            "Epoch 108/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1264 - factorized_top_k/top_5_categorical_accuracy: 0.7424 - factorized_top_k/top_10_categorical_accuracy: 0.8854 - factorized_top_k/top_50_categorical_accuracy: 0.9949 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13655.5364 - regularization_loss: 0.0000e+00 - total_loss: 13655.5364\n",
            "Epoch 109/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1285 - factorized_top_k/top_5_categorical_accuracy: 0.7428 - factorized_top_k/top_10_categorical_accuracy: 0.8849 - factorized_top_k/top_50_categorical_accuracy: 0.9949 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13651.9888 - regularization_loss: 0.0000e+00 - total_loss: 13651.9888\n",
            "Epoch 110/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1268 - factorized_top_k/top_5_categorical_accuracy: 0.7435 - factorized_top_k/top_10_categorical_accuracy: 0.8854 - factorized_top_k/top_50_categorical_accuracy: 0.9950 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13648.4966 - regularization_loss: 0.0000e+00 - total_loss: 13648.4966\n",
            "Epoch 111/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1277 - factorized_top_k/top_5_categorical_accuracy: 0.7431 - factorized_top_k/top_10_categorical_accuracy: 0.8855 - factorized_top_k/top_50_categorical_accuracy: 0.9951 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13645.0491 - regularization_loss: 0.0000e+00 - total_loss: 13645.0491\n",
            "Epoch 112/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1276 - factorized_top_k/top_5_categorical_accuracy: 0.7432 - factorized_top_k/top_10_categorical_accuracy: 0.8856 - factorized_top_k/top_50_categorical_accuracy: 0.9951 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13641.6519 - regularization_loss: 0.0000e+00 - total_loss: 13641.6519\n",
            "Epoch 113/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1270 - factorized_top_k/top_5_categorical_accuracy: 0.7432 - factorized_top_k/top_10_categorical_accuracy: 0.8859 - factorized_top_k/top_50_categorical_accuracy: 0.9951 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13638.3035 - regularization_loss: 0.0000e+00 - total_loss: 13638.3035\n",
            "Epoch 114/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1280 - factorized_top_k/top_5_categorical_accuracy: 0.7437 - factorized_top_k/top_10_categorical_accuracy: 0.8868 - factorized_top_k/top_50_categorical_accuracy: 0.9952 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13634.9973 - regularization_loss: 0.0000e+00 - total_loss: 13634.9973\n",
            "Epoch 115/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1273 - factorized_top_k/top_5_categorical_accuracy: 0.7435 - factorized_top_k/top_10_categorical_accuracy: 0.8867 - factorized_top_k/top_50_categorical_accuracy: 0.9952 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13631.7434 - regularization_loss: 0.0000e+00 - total_loss: 13631.7434\n",
            "Epoch 116/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1281 - factorized_top_k/top_5_categorical_accuracy: 0.7439 - factorized_top_k/top_10_categorical_accuracy: 0.8866 - factorized_top_k/top_50_categorical_accuracy: 0.9952 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13628.5259 - regularization_loss: 0.0000e+00 - total_loss: 13628.5259\n",
            "Epoch 117/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1272 - factorized_top_k/top_5_categorical_accuracy: 0.7442 - factorized_top_k/top_10_categorical_accuracy: 0.8870 - factorized_top_k/top_50_categorical_accuracy: 0.9952 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13625.3591 - regularization_loss: 0.0000e+00 - total_loss: 13625.3591\n",
            "Epoch 118/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1285 - factorized_top_k/top_5_categorical_accuracy: 0.7441 - factorized_top_k/top_10_categorical_accuracy: 0.8873 - factorized_top_k/top_50_categorical_accuracy: 0.9952 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 13622.2271 - regularization_loss: 0.0000e+00 - total_loss: 13622.2271\n",
            "Epoch 119/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1282 - factorized_top_k/top_5_categorical_accuracy: 0.7442 - factorized_top_k/top_10_categorical_accuracy: 0.8876 - factorized_top_k/top_50_categorical_accuracy: 0.9953 - factorized_top_k/top_100_categorical_accuracy: 0.9993 - loss: 13619.1433 - regularization_loss: 0.0000e+00 - total_loss: 13619.1433\n",
            "Epoch 120/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1290 - factorized_top_k/top_5_categorical_accuracy: 0.7441 - factorized_top_k/top_10_categorical_accuracy: 0.8876 - factorized_top_k/top_50_categorical_accuracy: 0.9953 - factorized_top_k/top_100_categorical_accuracy: 0.9993 - loss: 13616.0933 - regularization_loss: 0.0000e+00 - total_loss: 13616.0933\n",
            "Epoch 121/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1284 - factorized_top_k/top_5_categorical_accuracy: 0.7444 - factorized_top_k/top_10_categorical_accuracy: 0.8880 - factorized_top_k/top_50_categorical_accuracy: 0.9953 - factorized_top_k/top_100_categorical_accuracy: 0.9993 - loss: 13613.0889 - regularization_loss: 0.0000e+00 - total_loss: 13613.0889\n",
            "Epoch 122/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1297 - factorized_top_k/top_5_categorical_accuracy: 0.7448 - factorized_top_k/top_10_categorical_accuracy: 0.8884 - factorized_top_k/top_50_categorical_accuracy: 0.9953 - factorized_top_k/top_100_categorical_accuracy: 0.9993 - loss: 13610.1179 - regularization_loss: 0.0000e+00 - total_loss: 13610.1179\n",
            "Epoch 123/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1285 - factorized_top_k/top_5_categorical_accuracy: 0.7446 - factorized_top_k/top_10_categorical_accuracy: 0.8886 - factorized_top_k/top_50_categorical_accuracy: 0.9953 - factorized_top_k/top_100_categorical_accuracy: 0.9993 - loss: 13607.1895 - regularization_loss: 0.0000e+00 - total_loss: 13607.1895\n",
            "Epoch 124/200\n",
            "3/3 [==============================] - 7s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1303 - factorized_top_k/top_5_categorical_accuracy: 0.7449 - factorized_top_k/top_10_categorical_accuracy: 0.8886 - factorized_top_k/top_50_categorical_accuracy: 0.9953 - factorized_top_k/top_100_categorical_accuracy: 0.9993 - loss: 13604.2922 - regularization_loss: 0.0000e+00 - total_loss: 13604.2922\n",
            "Epoch 125/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1289 - factorized_top_k/top_5_categorical_accuracy: 0.7455 - factorized_top_k/top_10_categorical_accuracy: 0.8888 - factorized_top_k/top_50_categorical_accuracy: 0.9954 - factorized_top_k/top_100_categorical_accuracy: 0.9993 - loss: 13601.4375 - regularization_loss: 0.0000e+00 - total_loss: 13601.4375\n",
            "Epoch 126/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1309 - factorized_top_k/top_5_categorical_accuracy: 0.7457 - factorized_top_k/top_10_categorical_accuracy: 0.8889 - factorized_top_k/top_50_categorical_accuracy: 0.9954 - factorized_top_k/top_100_categorical_accuracy: 0.9993 - loss: 13598.6101 - regularization_loss: 0.0000e+00 - total_loss: 13598.6101\n",
            "Epoch 127/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1291 - factorized_top_k/top_5_categorical_accuracy: 0.7459 - factorized_top_k/top_10_categorical_accuracy: 0.8889 - factorized_top_k/top_50_categorical_accuracy: 0.9954 - factorized_top_k/top_100_categorical_accuracy: 0.9993 - loss: 13595.8259 - regularization_loss: 0.0000e+00 - total_loss: 13595.8259\n",
            "Epoch 128/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1311 - factorized_top_k/top_5_categorical_accuracy: 0.7459 - factorized_top_k/top_10_categorical_accuracy: 0.8891 - factorized_top_k/top_50_categorical_accuracy: 0.9954 - factorized_top_k/top_100_categorical_accuracy: 0.9993 - loss: 13593.0640 - regularization_loss: 0.0000e+00 - total_loss: 13593.0640\n",
            "Epoch 129/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1299 - factorized_top_k/top_5_categorical_accuracy: 0.7461 - factorized_top_k/top_10_categorical_accuracy: 0.8891 - factorized_top_k/top_50_categorical_accuracy: 0.9954 - factorized_top_k/top_100_categorical_accuracy: 0.9993 - loss: 13590.3484 - regularization_loss: 0.0000e+00 - total_loss: 13590.3484\n",
            "Epoch 130/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1314 - factorized_top_k/top_5_categorical_accuracy: 0.7465 - factorized_top_k/top_10_categorical_accuracy: 0.8892 - factorized_top_k/top_50_categorical_accuracy: 0.9955 - factorized_top_k/top_100_categorical_accuracy: 0.9993 - loss: 13587.6514 - regularization_loss: 0.0000e+00 - total_loss: 13587.6514\n",
            "Epoch 131/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1302 - factorized_top_k/top_5_categorical_accuracy: 0.7466 - factorized_top_k/top_10_categorical_accuracy: 0.8894 - factorized_top_k/top_50_categorical_accuracy: 0.9955 - factorized_top_k/top_100_categorical_accuracy: 0.9993 - loss: 13585.0007 - regularization_loss: 0.0000e+00 - total_loss: 13585.0007\n",
            "Epoch 132/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1315 - factorized_top_k/top_5_categorical_accuracy: 0.7472 - factorized_top_k/top_10_categorical_accuracy: 0.8895 - factorized_top_k/top_50_categorical_accuracy: 0.9955 - factorized_top_k/top_100_categorical_accuracy: 0.9993 - loss: 13582.3655 - regularization_loss: 0.0000e+00 - total_loss: 13582.3655\n",
            "Epoch 133/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1310 - factorized_top_k/top_5_categorical_accuracy: 0.7470 - factorized_top_k/top_10_categorical_accuracy: 0.8897 - factorized_top_k/top_50_categorical_accuracy: 0.9955 - factorized_top_k/top_100_categorical_accuracy: 0.9993 - loss: 13579.7771 - regularization_loss: 0.0000e+00 - total_loss: 13579.7771\n",
            "Epoch 134/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1319 - factorized_top_k/top_5_categorical_accuracy: 0.7469 - factorized_top_k/top_10_categorical_accuracy: 0.8899 - factorized_top_k/top_50_categorical_accuracy: 0.9955 - factorized_top_k/top_100_categorical_accuracy: 0.9993 - loss: 13577.2024 - regularization_loss: 0.0000e+00 - total_loss: 13577.2024\n",
            "Epoch 135/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1310 - factorized_top_k/top_5_categorical_accuracy: 0.7470 - factorized_top_k/top_10_categorical_accuracy: 0.8897 - factorized_top_k/top_50_categorical_accuracy: 0.9956 - factorized_top_k/top_100_categorical_accuracy: 0.9993 - loss: 13574.6729 - regularization_loss: 0.0000e+00 - total_loss: 13574.6729\n",
            "Epoch 136/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1318 - factorized_top_k/top_5_categorical_accuracy: 0.7478 - factorized_top_k/top_10_categorical_accuracy: 0.8901 - factorized_top_k/top_50_categorical_accuracy: 0.9957 - factorized_top_k/top_100_categorical_accuracy: 0.9993 - loss: 13572.1582 - regularization_loss: 0.0000e+00 - total_loss: 13572.1582\n",
            "Epoch 137/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1312 - factorized_top_k/top_5_categorical_accuracy: 0.7477 - factorized_top_k/top_10_categorical_accuracy: 0.8900 - factorized_top_k/top_50_categorical_accuracy: 0.9957 - factorized_top_k/top_100_categorical_accuracy: 0.9993 - loss: 13569.6863 - regularization_loss: 0.0000e+00 - total_loss: 13569.6863\n",
            "Epoch 138/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1312 - factorized_top_k/top_5_categorical_accuracy: 0.7478 - factorized_top_k/top_10_categorical_accuracy: 0.8900 - factorized_top_k/top_50_categorical_accuracy: 0.9957 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13567.2285 - regularization_loss: 0.0000e+00 - total_loss: 13567.2285\n",
            "Epoch 139/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1316 - factorized_top_k/top_5_categorical_accuracy: 0.7479 - factorized_top_k/top_10_categorical_accuracy: 0.8902 - factorized_top_k/top_50_categorical_accuracy: 0.9957 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13564.8105 - regularization_loss: 0.0000e+00 - total_loss: 13564.8105\n",
            "Epoch 140/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1312 - factorized_top_k/top_5_categorical_accuracy: 0.7480 - factorized_top_k/top_10_categorical_accuracy: 0.8905 - factorized_top_k/top_50_categorical_accuracy: 0.9957 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13562.4080 - regularization_loss: 0.0000e+00 - total_loss: 13562.4080\n",
            "Epoch 141/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1313 - factorized_top_k/top_5_categorical_accuracy: 0.7476 - factorized_top_k/top_10_categorical_accuracy: 0.8906 - factorized_top_k/top_50_categorical_accuracy: 0.9956 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13560.0413 - regularization_loss: 0.0000e+00 - total_loss: 13560.0413\n",
            "Epoch 142/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1307 - factorized_top_k/top_5_categorical_accuracy: 0.7479 - factorized_top_k/top_10_categorical_accuracy: 0.8906 - factorized_top_k/top_50_categorical_accuracy: 0.9956 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13557.6914 - regularization_loss: 0.0000e+00 - total_loss: 13557.6914\n",
            "Epoch 143/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1315 - factorized_top_k/top_5_categorical_accuracy: 0.7476 - factorized_top_k/top_10_categorical_accuracy: 0.8910 - factorized_top_k/top_50_categorical_accuracy: 0.9956 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13555.3740 - regularization_loss: 0.0000e+00 - total_loss: 13555.3740\n",
            "Epoch 144/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1305 - factorized_top_k/top_5_categorical_accuracy: 0.7480 - factorized_top_k/top_10_categorical_accuracy: 0.8912 - factorized_top_k/top_50_categorical_accuracy: 0.9956 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13553.0759 - regularization_loss: 0.0000e+00 - total_loss: 13553.0759\n",
            "Epoch 145/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1315 - factorized_top_k/top_5_categorical_accuracy: 0.7477 - factorized_top_k/top_10_categorical_accuracy: 0.8914 - factorized_top_k/top_50_categorical_accuracy: 0.9957 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13550.8049 - regularization_loss: 0.0000e+00 - total_loss: 13550.8049\n",
            "Epoch 146/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1304 - factorized_top_k/top_5_categorical_accuracy: 0.7483 - factorized_top_k/top_10_categorical_accuracy: 0.8915 - factorized_top_k/top_50_categorical_accuracy: 0.9957 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13548.5544 - regularization_loss: 0.0000e+00 - total_loss: 13548.5544\n",
            "Epoch 147/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1319 - factorized_top_k/top_5_categorical_accuracy: 0.7478 - factorized_top_k/top_10_categorical_accuracy: 0.8914 - factorized_top_k/top_50_categorical_accuracy: 0.9957 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13546.3269 - regularization_loss: 0.0000e+00 - total_loss: 13546.3269\n",
            "Epoch 148/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1306 - factorized_top_k/top_5_categorical_accuracy: 0.7483 - factorized_top_k/top_10_categorical_accuracy: 0.8915 - factorized_top_k/top_50_categorical_accuracy: 0.9958 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13544.1260 - regularization_loss: 0.0000e+00 - total_loss: 13544.1260\n",
            "Epoch 149/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1320 - factorized_top_k/top_5_categorical_accuracy: 0.7480 - factorized_top_k/top_10_categorical_accuracy: 0.8915 - factorized_top_k/top_50_categorical_accuracy: 0.9958 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13541.9414 - regularization_loss: 0.0000e+00 - total_loss: 13541.9414\n",
            "Epoch 150/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1310 - factorized_top_k/top_5_categorical_accuracy: 0.7485 - factorized_top_k/top_10_categorical_accuracy: 0.8917 - factorized_top_k/top_50_categorical_accuracy: 0.9958 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13539.7864 - regularization_loss: 0.0000e+00 - total_loss: 13539.7864\n",
            "Epoch 151/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1338 - factorized_top_k/top_5_categorical_accuracy: 0.7484 - factorized_top_k/top_10_categorical_accuracy: 0.8915 - factorized_top_k/top_50_categorical_accuracy: 0.9957 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13537.6438 - regularization_loss: 0.0000e+00 - total_loss: 13537.6438\n",
            "Epoch 152/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1314 - factorized_top_k/top_5_categorical_accuracy: 0.7483 - factorized_top_k/top_10_categorical_accuracy: 0.8917 - factorized_top_k/top_50_categorical_accuracy: 0.9957 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13535.5347 - regularization_loss: 0.0000e+00 - total_loss: 13535.5347\n",
            "Epoch 153/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1340 - factorized_top_k/top_5_categorical_accuracy: 0.7486 - factorized_top_k/top_10_categorical_accuracy: 0.8920 - factorized_top_k/top_50_categorical_accuracy: 0.9958 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13533.4331 - regularization_loss: 0.0000e+00 - total_loss: 13533.4331\n",
            "Epoch 154/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1319 - factorized_top_k/top_5_categorical_accuracy: 0.7489 - factorized_top_k/top_10_categorical_accuracy: 0.8922 - factorized_top_k/top_50_categorical_accuracy: 0.9959 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13531.3669 - regularization_loss: 0.0000e+00 - total_loss: 13531.3669\n",
            "Epoch 155/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1344 - factorized_top_k/top_5_categorical_accuracy: 0.7492 - factorized_top_k/top_10_categorical_accuracy: 0.8924 - factorized_top_k/top_50_categorical_accuracy: 0.9960 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13529.3052 - regularization_loss: 0.0000e+00 - total_loss: 13529.3052\n",
            "Epoch 156/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1321 - factorized_top_k/top_5_categorical_accuracy: 0.7494 - factorized_top_k/top_10_categorical_accuracy: 0.8925 - factorized_top_k/top_50_categorical_accuracy: 0.9960 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13527.2825 - regularization_loss: 0.0000e+00 - total_loss: 13527.2825\n",
            "Epoch 157/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1346 - factorized_top_k/top_5_categorical_accuracy: 0.7496 - factorized_top_k/top_10_categorical_accuracy: 0.8927 - factorized_top_k/top_50_categorical_accuracy: 0.9960 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13525.2583 - regularization_loss: 0.0000e+00 - total_loss: 13525.2583\n",
            "Epoch 158/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1320 - factorized_top_k/top_5_categorical_accuracy: 0.7497 - factorized_top_k/top_10_categorical_accuracy: 0.8932 - factorized_top_k/top_50_categorical_accuracy: 0.9960 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13523.2769 - regularization_loss: 0.0000e+00 - total_loss: 13523.2769\n",
            "Epoch 159/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1352 - factorized_top_k/top_5_categorical_accuracy: 0.7499 - factorized_top_k/top_10_categorical_accuracy: 0.8933 - factorized_top_k/top_50_categorical_accuracy: 0.9960 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13521.2893 - regularization_loss: 0.0000e+00 - total_loss: 13521.2893\n",
            "Epoch 160/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1322 - factorized_top_k/top_5_categorical_accuracy: 0.7497 - factorized_top_k/top_10_categorical_accuracy: 0.8934 - factorized_top_k/top_50_categorical_accuracy: 0.9960 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13519.3481 - regularization_loss: 0.0000e+00 - total_loss: 13519.3481\n",
            "Epoch 161/200\n",
            "3/3 [==============================] - 8s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.1346 - factorized_top_k/top_5_categorical_accuracy: 0.7498 - factorized_top_k/top_10_categorical_accuracy: 0.8936 - factorized_top_k/top_50_categorical_accuracy: 0.9960 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13517.3970 - regularization_loss: 0.0000e+00 - total_loss: 13517.3970\n",
            "Epoch 162/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1324 - factorized_top_k/top_5_categorical_accuracy: 0.7498 - factorized_top_k/top_10_categorical_accuracy: 0.8936 - factorized_top_k/top_50_categorical_accuracy: 0.9960 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13515.4944 - regularization_loss: 0.0000e+00 - total_loss: 13515.4944\n",
            "Epoch 163/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1346 - factorized_top_k/top_5_categorical_accuracy: 0.7500 - factorized_top_k/top_10_categorical_accuracy: 0.8939 - factorized_top_k/top_50_categorical_accuracy: 0.9959 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13513.5767 - regularization_loss: 0.0000e+00 - total_loss: 13513.5767\n",
            "Epoch 164/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1325 - factorized_top_k/top_5_categorical_accuracy: 0.7498 - factorized_top_k/top_10_categorical_accuracy: 0.8942 - factorized_top_k/top_50_categorical_accuracy: 0.9960 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13511.7119 - regularization_loss: 0.0000e+00 - total_loss: 13511.7119\n",
            "Epoch 165/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1346 - factorized_top_k/top_5_categorical_accuracy: 0.7499 - factorized_top_k/top_10_categorical_accuracy: 0.8947 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13509.8291 - regularization_loss: 0.0000e+00 - total_loss: 13509.8291\n",
            "Epoch 166/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1328 - factorized_top_k/top_5_categorical_accuracy: 0.7499 - factorized_top_k/top_10_categorical_accuracy: 0.8946 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13507.9988 - regularization_loss: 0.0000e+00 - total_loss: 13507.9988\n",
            "Epoch 167/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1350 - factorized_top_k/top_5_categorical_accuracy: 0.7500 - factorized_top_k/top_10_categorical_accuracy: 0.8947 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13506.1487 - regularization_loss: 0.0000e+00 - total_loss: 13506.1487\n",
            "Epoch 168/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1333 - factorized_top_k/top_5_categorical_accuracy: 0.7502 - factorized_top_k/top_10_categorical_accuracy: 0.8950 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13504.3513 - regularization_loss: 0.0000e+00 - total_loss: 13504.3513\n",
            "Epoch 169/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1352 - factorized_top_k/top_5_categorical_accuracy: 0.7503 - factorized_top_k/top_10_categorical_accuracy: 0.8951 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13502.5342 - regularization_loss: 0.0000e+00 - total_loss: 13502.5342\n",
            "Epoch 170/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1335 - factorized_top_k/top_5_categorical_accuracy: 0.7503 - factorized_top_k/top_10_categorical_accuracy: 0.8952 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13500.7690 - regularization_loss: 0.0000e+00 - total_loss: 13500.7690\n",
            "Epoch 171/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1355 - factorized_top_k/top_5_categorical_accuracy: 0.7499 - factorized_top_k/top_10_categorical_accuracy: 0.8954 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13498.9836 - regularization_loss: 0.0000e+00 - total_loss: 13498.9836\n",
            "Epoch 172/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1336 - factorized_top_k/top_5_categorical_accuracy: 0.7502 - factorized_top_k/top_10_categorical_accuracy: 0.8954 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13497.2490 - regularization_loss: 0.0000e+00 - total_loss: 13497.2490\n",
            "Epoch 173/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1359 - factorized_top_k/top_5_categorical_accuracy: 0.7500 - factorized_top_k/top_10_categorical_accuracy: 0.8955 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13495.4941 - regularization_loss: 0.0000e+00 - total_loss: 13495.4941\n",
            "Epoch 174/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1336 - factorized_top_k/top_5_categorical_accuracy: 0.7507 - factorized_top_k/top_10_categorical_accuracy: 0.8957 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13493.7861 - regularization_loss: 0.0000e+00 - total_loss: 13493.7861\n",
            "Epoch 175/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1364 - factorized_top_k/top_5_categorical_accuracy: 0.7502 - factorized_top_k/top_10_categorical_accuracy: 0.8957 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13492.0615 - regularization_loss: 0.0000e+00 - total_loss: 13492.0615\n",
            "Epoch 176/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1330 - factorized_top_k/top_5_categorical_accuracy: 0.7510 - factorized_top_k/top_10_categorical_accuracy: 0.8959 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13490.3809 - regularization_loss: 0.0000e+00 - total_loss: 13490.3809\n",
            "Epoch 177/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1369 - factorized_top_k/top_5_categorical_accuracy: 0.7507 - factorized_top_k/top_10_categorical_accuracy: 0.8961 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13488.6858 - regularization_loss: 0.0000e+00 - total_loss: 13488.6858\n",
            "Epoch 178/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1327 - factorized_top_k/top_5_categorical_accuracy: 0.7513 - factorized_top_k/top_10_categorical_accuracy: 0.8961 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13487.0327 - regularization_loss: 0.0000e+00 - total_loss: 13487.0327\n",
            "Epoch 179/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1373 - factorized_top_k/top_5_categorical_accuracy: 0.7511 - factorized_top_k/top_10_categorical_accuracy: 0.8962 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13485.3677 - regularization_loss: 0.0000e+00 - total_loss: 13485.3677\n",
            "Epoch 180/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1327 - factorized_top_k/top_5_categorical_accuracy: 0.7515 - factorized_top_k/top_10_categorical_accuracy: 0.8965 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13483.7395 - regularization_loss: 0.0000e+00 - total_loss: 13483.7395\n",
            "Epoch 181/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1371 - factorized_top_k/top_5_categorical_accuracy: 0.7512 - factorized_top_k/top_10_categorical_accuracy: 0.8965 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13482.1047 - regularization_loss: 0.0000e+00 - total_loss: 13482.1047\n",
            "Epoch 182/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1327 - factorized_top_k/top_5_categorical_accuracy: 0.7518 - factorized_top_k/top_10_categorical_accuracy: 0.8964 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13480.5039 - regularization_loss: 0.0000e+00 - total_loss: 13480.5039\n",
            "Epoch 183/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1370 - factorized_top_k/top_5_categorical_accuracy: 0.7519 - factorized_top_k/top_10_categorical_accuracy: 0.8966 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13478.8958 - regularization_loss: 0.0000e+00 - total_loss: 13478.8958\n",
            "Epoch 184/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1330 - factorized_top_k/top_5_categorical_accuracy: 0.7525 - factorized_top_k/top_10_categorical_accuracy: 0.8968 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13477.3201 - regularization_loss: 0.0000e+00 - total_loss: 13477.3201\n",
            "Epoch 185/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1373 - factorized_top_k/top_5_categorical_accuracy: 0.7527 - factorized_top_k/top_10_categorical_accuracy: 0.8970 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13475.7397 - regularization_loss: 0.0000e+00 - total_loss: 13475.7397\n",
            "Epoch 186/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1329 - factorized_top_k/top_5_categorical_accuracy: 0.7527 - factorized_top_k/top_10_categorical_accuracy: 0.8973 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13474.1882 - regularization_loss: 0.0000e+00 - total_loss: 13474.1882\n",
            "Epoch 187/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1375 - factorized_top_k/top_5_categorical_accuracy: 0.7532 - factorized_top_k/top_10_categorical_accuracy: 0.8972 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13472.6348 - regularization_loss: 0.0000e+00 - total_loss: 13472.6348\n",
            "Epoch 188/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1328 - factorized_top_k/top_5_categorical_accuracy: 0.7528 - factorized_top_k/top_10_categorical_accuracy: 0.8972 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13471.1079 - regularization_loss: 0.0000e+00 - total_loss: 13471.1079\n",
            "Epoch 189/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1374 - factorized_top_k/top_5_categorical_accuracy: 0.7529 - factorized_top_k/top_10_categorical_accuracy: 0.8973 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13469.5793 - regularization_loss: 0.0000e+00 - total_loss: 13469.5793\n",
            "Epoch 190/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1331 - factorized_top_k/top_5_categorical_accuracy: 0.7527 - factorized_top_k/top_10_categorical_accuracy: 0.8974 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13468.0754 - regularization_loss: 0.0000e+00 - total_loss: 13468.0754\n",
            "Epoch 191/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1375 - factorized_top_k/top_5_categorical_accuracy: 0.7530 - factorized_top_k/top_10_categorical_accuracy: 0.8975 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13466.5728 - regularization_loss: 0.0000e+00 - total_loss: 13466.5728\n",
            "Epoch 192/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1335 - factorized_top_k/top_5_categorical_accuracy: 0.7533 - factorized_top_k/top_10_categorical_accuracy: 0.8975 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13465.0913 - regularization_loss: 0.0000e+00 - total_loss: 13465.0913\n",
            "Epoch 193/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1375 - factorized_top_k/top_5_categorical_accuracy: 0.7536 - factorized_top_k/top_10_categorical_accuracy: 0.8978 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13463.6121 - regularization_loss: 0.0000e+00 - total_loss: 13463.6121\n",
            "Epoch 194/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1334 - factorized_top_k/top_5_categorical_accuracy: 0.7534 - factorized_top_k/top_10_categorical_accuracy: 0.8978 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13462.1533 - regularization_loss: 0.0000e+00 - total_loss: 13462.1533\n",
            "Epoch 195/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1374 - factorized_top_k/top_5_categorical_accuracy: 0.7534 - factorized_top_k/top_10_categorical_accuracy: 0.8980 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13460.6987 - regularization_loss: 0.0000e+00 - total_loss: 13460.6987\n",
            "Epoch 196/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1335 - factorized_top_k/top_5_categorical_accuracy: 0.7532 - factorized_top_k/top_10_categorical_accuracy: 0.8979 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13459.2612 - regularization_loss: 0.0000e+00 - total_loss: 13459.2612\n",
            "Epoch 197/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1376 - factorized_top_k/top_5_categorical_accuracy: 0.7537 - factorized_top_k/top_10_categorical_accuracy: 0.8980 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13457.8298 - regularization_loss: 0.0000e+00 - total_loss: 13457.8298\n",
            "Epoch 198/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1338 - factorized_top_k/top_5_categorical_accuracy: 0.7535 - factorized_top_k/top_10_categorical_accuracy: 0.8980 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13456.4121 - regularization_loss: 0.0000e+00 - total_loss: 13456.4121\n",
            "Epoch 199/200\n",
            "3/3 [==============================] - 6s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1378 - factorized_top_k/top_5_categorical_accuracy: 0.7537 - factorized_top_k/top_10_categorical_accuracy: 0.8985 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13455.0039 - regularization_loss: 0.0000e+00 - total_loss: 13455.0039\n",
            "Epoch 200/200\n",
            "3/3 [==============================] - 7s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1341 - factorized_top_k/top_5_categorical_accuracy: 0.7537 - factorized_top_k/top_10_categorical_accuracy: 0.8986 - factorized_top_k/top_50_categorical_accuracy: 0.9962 - factorized_top_k/top_100_categorical_accuracy: 0.9994 - loss: 13453.6069 - regularization_loss: 0.0000e+00 - total_loss: 13453.6069\n"
          ]
        }
      ],
      "source": [
        "hist = model.fit(cached_train, epochs=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Mc7_GYoLiDg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "top10train = hist.history['factorized_top_k/top_10_categorical_accuracy']\n",
        "plt.plot(top10train, color='r', label='Top 10 Train')\n",
        "\n",
        "plt.title(\"Top 10 Accuracy Curve\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "-ic1VhQGMbPc",
        "outputId": "cb93459b-bf37-4040-9747-49ea02cb09fb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist2 =  model.evaluate(cached_test, return_dict=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvZV5fUgNq4O",
        "outputId": "d9fb02e1-5fd7-41b6-968d-9c644d0d1773"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.1690 - factorized_top_k/top_5_categorical_accuracy: 0.7155 - factorized_top_k/top_10_categorical_accuracy: 0.8795 - factorized_top_k/top_50_categorical_accuracy: 0.9975 - factorized_top_k/top_100_categorical_accuracy: 0.9995 - loss: 9057.4453 - regularization_loss: 0.0000e+00 - total_loss: 9057.4453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In train model we get top_10_categorical_accuracy: 0.8986, and in evaluate model we get top_10_categorical_accuracy: 0.8795."
      ],
      "metadata": {
        "id": "OHKUZ2Moie9F"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU8rvPexUk5F"
      },
      "source": [
        "# It's time for recommendation!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have a model, we want to be able to make predictions. We can use the tfrs.layers.factorized_top_k.BruteForce layer to do this."
      ],
      "metadata": {
        "id": "PTtdOllSTPbl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "2rWUNdynLI5R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd13a68a-07ee-47ae-ad84-a54d0f3282f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations from Harry Potter and the Philosopher's Stone :\n",
            "Harry Potter and the Philosopher's Stone\n",
            " score :24.923816680908203\n",
            "Harry Potter and the Half-Blood Prince\n",
            " score :20.211181640625\n",
            "Harry Potter Collection (Harry Potter, #1-6)\n",
            " score :19.695627212524414\n",
            "Harry Potter and the Prisoner of Azkaban\n",
            " score :19.657434463500977\n",
            "The Hitchhiker's Guide to the Galaxy\n",
            " score :18.516090393066406\n",
            "Notes from a Small Island\n",
            " score :18.170305252075195\n",
            "The Lord of the Rings\n",
            " score :17.936767578125\n",
            "The Lord of the Rings: Weapons and Warfare\n",
            " score :17.43825912475586\n",
            "Harry Potter and the Order of the Phoenix\n",
            " score :17.067462921142578\n",
            "Heidi\n",
            " score :16.885114669799805\n"
          ]
        }
      ],
      "source": [
        "index = tfrs.layers.factorized_top_k.BruteForce(model.book_model)\n",
        "index.index_from_dataset(\n",
        "  tf.data.Dataset.zip((books.batch(100), books.batch(100).map(model.book_model)))\n",
        ")\n",
        "\n",
        "input = \"Harry Potter and the Philosopher's Stone\"\n",
        "\n",
        "score, titles = index(tf.constant([input]))\n",
        "print(f\"Recommendations from {input} :\")\n",
        "result_book=titles[0, :10].numpy().tolist()\n",
        "result_score=score[0, :10].numpy().tolist()\n",
        "for i in range(len(result_book)):\n",
        "  print(result_book[i].decode())\n",
        "  print(\" score :\"+str(result_score[i]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = \"Batman, Volume 3: Death of the Family\"\n",
        "\n",
        "score, titles = index(tf.constant([input]))\n",
        "print(f\"Recommendations from {input} :\")\n",
        "result_book=titles[0, :10].numpy().tolist()\n",
        "for i in range(len(result_book)):\n",
        "  print(result_book[i].decode())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXyoz7CaVVrJ",
        "outputId": "77930b59-90a8-4e1a-a566-ee9d82127e85"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations from Batman, Volume 3: Death of the Family :\n",
            "Cien años de soledad\n",
            "The Salmon of Doubt: Hitchhiking the Galaxy One Last Time\n",
            "The Elegant Universe: Superstrings, Hidden Dimensions, and the Quest for the Ultimate Theory\n",
            "Sailing Alone Around the Room: New and Selected Poems\n",
            "The Life and Adventures of Martin Chuzzlewit\n",
            "The Time Machine\n",
            "The Tipping Point: How Little Things Can Make a Big Difference\n",
            "The War of Art: Break Through the Blocks and Win Your Inner Creative Battles\n",
            "Children of Dune\n",
            "The Men Who Stare at Goats\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = \"The Hunger Game\"\n",
        "\n",
        "score, titles = index(tf.constant([input]))\n",
        "print(f\"Recommendations from {input} :\")\n",
        "result_book=titles[0, :10].numpy().tolist()\n",
        "for i in range(len(result_book)):\n",
        "  print(result_book[i].decode())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdjR_XL6Ws9J",
        "outputId": "e6a7e2f1-06ca-4e0a-baae-b3641e37ef8f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations from The Hunger Game :\n",
            "The Brooklyn Follies\n",
            " The Fellowship of the Ring\n",
            "O Alquimista\n",
            "Truman\n",
            "Quicksilver\n",
            "To Kill a Mockingbird\n",
            "Pompeii\n",
            "Todos os Nomes\n",
            "The Psychology of Everyday Things\n",
            "Job: A Comedy of Justice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcOwwRW9Q2oF"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOI5jnDA5rEG"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "mktR4Wj277oc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save model to saved_model.pb"
      ],
      "metadata": {
        "id": "P1eLSYTiTok8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "LnOgz1tzQwnT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "731c2398-fb92-4b66-be8e-f8740c16a205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/model/assets\n"
          ]
        }
      ],
      "source": [
        "curr = os.getcwd()\n",
        "\n",
        "path = os.path.join(curr, \"model\")\n",
        "\n",
        "tf.saved_model.save(index, path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruocNwx65vik"
      },
      "source": [
        "# Convert to Tflite"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chose optimize, convert to tflite, and save in model.tflite"
      ],
      "metadata": {
        "id": "QKF0M5NkTvZM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "cZQ1UOjyHS9g"
      },
      "outputs": [],
      "source": [
        "mode = \"Speed\" \n",
        "\n",
        "if mode == 'Storage':\n",
        "    optimization = tf.lite.Optimize.OPTIMIZE_FOR_SIZE\n",
        "elif mode == 'Speed':\n",
        "    optimization = tf.lite.Optimize.OPTIMIZE_FOR_LATENCY\n",
        "else:\n",
        "    optimization = tf.lite.Optimize.DEFAULT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "FBoxTCtT8VD0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9a957c3-7b6a-4b0c-b8b6-ccd15c179303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Optimization option OPTIMIZE_FOR_LATENCY is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_LATENCY is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_LATENCY is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(path)\n",
        "\n",
        "converter.optimizations =[optimization] \n",
        "\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_model_file = pathlib.Path('./model.tflite')\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phzn44kNTks8",
        "outputId": "ea2dacad-38e6-4af8-9063-cdacb232a819"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "886368"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "#download saved_model and other file in folder model\n",
        "!zip -r /content/modeldownload.zip /content/model\n",
        "files.download('/content/modeldownload.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "hISSkDJpQ_39",
        "outputId": "084aaa7d-f65d-48bd-cc94-40b7fe8b671d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: content/model/ (stored 0%)\n",
            "updating: content/model/variables/ (stored 0%)\n",
            "updating: content/model/variables/variables.data-00000-of-00001 (deflated 15%)\n",
            "updating: content/model/variables/variables.index (deflated 33%)\n",
            "updating: content/model/assets/ (stored 0%)\n",
            "updating: content/model/saved_model.pb (deflated 66%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3342c1c0-287e-40a8-a142-e837930131d6\", \"modeldownload.zip\", 1337273)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download tflite\n",
        "files.download('/content/model.tflite')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "p4i00B44SDKF",
        "outputId": "fcd1fc8e-41f4-437d-eeca-d31752e3b8ce"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_992ee7be-365b-43c6-a8ba-1019aa8e3804\", \"model.tflite\", 886368)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Book_Recommendation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}